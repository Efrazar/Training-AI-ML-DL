{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9f0d99-cb75-4510-9635-52542982aac9",
   "metadata": {},
   "source": [
    "# Principles of Deep Learning\n",
    "\n",
    "Thinking about deep learning as a biological process of adaptation can be very helpful. Let's break down how a neural network learns, which, at its core, is a cycle of guessing, checking, and correcting.\n",
    "\n",
    "Think of it like this: you're trying to teach a cell culture to respond to a new growth factor. You expose it, measure a response (e.g., protein expression), see how far off it is from the desired response, and then tweak the signaling pathway to get closer next time. The deep learning training loop is a mathematical formalization of that exact process.\n",
    "\n",
    "This entire cycle is often called training the model. It consists of four key steps that are repeated over and over.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6eeec-6234-4f89-b8a1-54ca129641ec",
   "metadata": {},
   "source": [
    "## 1. The Forward Pass: Making a Prediction ‚û°Ô∏è\n",
    "The forward pass (or forward propagation) is the process of your neural network making a guess. You take your input data‚Äîsay, a set of gene expression values from an RNA-seq experiment‚Äîand pass it forward through the network's layers.\n",
    "\n",
    "Each layer in the network is composed of \"neurons\" (nodes). A neuron receives inputs, performs a simple calculation, and passes the result to the next layer. This calculation is typically a weighted sum of its inputs, plus a value called a bias, which is then fed into an activation function.\n",
    "\n",
    "    Weighted Sum: This is just like a linear regression: z=(w1‚Äãx1‚Äã+w2‚Äãx2‚Äã+‚Ä¶)+b. The weights (w) are the most important part; they are the internal parameters the network will \"learn.\" Initially, they are random. They represent the strength of the connection between neurons, analogous to synaptic strength.\n",
    "\n",
    "    Activation Function: This function introduces non-linearity, which is critical. A biological neuron either fires or it doesn't‚Äîit's not a simple linear switch. An activation function like a ReLU (Rectified Linear Unit) or Sigmoid mimics this. It takes the weighted sum (z) and decides what the neuron's output should be.\n",
    "\n",
    "This process continues layer by layer until the final layer produces an output‚Äîthe network's prediction (y^‚Äã). For example, it might output a single number between 0 and 1, representing the probability that your input gene expression profile corresponds to a \"cancerous\" cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc1d4f0-ae2d-4155-a916-56f6e889e65a",
   "metadata": {},
   "source": [
    "## 2. Loss Calculation: Quantifying the Error üìâ\n",
    "Now that the network has made a prediction (y^‚Äã), we need to tell it how wrong it was. The loss function (also called a cost function or objective function) does exactly this. It compares the network's prediction (y^‚Äã) with the ground truth (the correct label, y), which you know from your experimental data.\n",
    "\n",
    "The result is a single number called the loss. A high loss means the prediction was terrible; a low loss means it was pretty good.\n",
    "\n",
    "A common loss function for classification tasks (like \"cancerous\" vs. \"healthy\") is Binary Cross-Entropy. The formula looks a bit intimidating, but the concept is simple: it heavily penalizes predictions that are confidently wrong.\\\n",
    "Loss=‚àí[ylog(y^‚Äã)+(1‚àíy)log(1‚àíy^‚Äã)]\n",
    "\n",
    "If the true label y=1 and your model predicts y^‚Äã=0.9 (90% confident it's 1), the loss is small. If it predicts y^‚Äã=0.1, the loss is huge!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be981468-e76d-4c5f-b848-1706ea3c31de",
   "metadata": {},
   "source": [
    "## 3. Backward Propagation: Assigning Blame ‚¨ÖÔ∏è\n",
    "This is the magic of deep learning. Now that we have the loss, we need to figure out which weights in the network were most responsible for the error and how to change them to do better next time. This process is called backward propagation or backprop.\n",
    "\n",
    "Using calculus (specifically the chain rule), backprop calculates the gradient of the loss with respect to every single weight and bias in the network. A gradient is essentially a vector that points in the direction of the steepest ascent of the loss function. Therefore, if we move the weights in the opposite direction of the gradient, we will decrease the loss.\n",
    "\n",
    "Think of it as a \"blame assignment\" algorithm. It starts from the loss and works its way backward through the network, layer by layer, calculating how much each weight contributed to the final error. A weight that had a large impact on the wrong output will get a large gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ce20d-e090-4efe-b530-fff8a0b8780c",
   "metadata": {},
   "source": [
    "## 4. Iteration and Optimization: Updating the Model üõ†Ô∏è\n",
    "he final step is to actually update the weights and biases using the gradients we just calculated. This is handled by an optimizer. The most fundamental optimizer is Stochastic Gradient Descent (SGD).\n",
    "\n",
    "The update rule is simple:\n",
    "new_weight=old_weight‚àí(learning_rate√ógradient)\n",
    "\n",
    "The learning rate is a small number (e.g., 0.01) that controls how big of a step we take. It's a critical hyperparameter:\n",
    "\n",
    "    Too high, and you might overshoot the optimal weights, like a clumsy scientist adding way too much reagent.\n",
    "\n",
    "    Too low, and the model will learn excruciatingly slowly.\n",
    "\n",
    "This entire four-step cycle‚Äîforward pass, loss calculation, backprop, and weight update‚Äîis one iteration. We repeat this process many times, usually by feeding the model data in small batches (e.g., 32 or 64 samples at a time). One full pass through the entire training dataset is called an epoch. After many epochs, the network's weights are finely tuned, and the loss is minimized. The model has learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af9cc7-64e5-4ea0-bd57-391f726a8fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(PyTorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
